{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ef85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import r2_score, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from utils import *\n",
    "from model import *\n",
    "from trainer import *\n",
    "import torch.utils.data as Dataset\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c471cf01",
   "metadata": {},
   "source": [
    "## Extracting and save PSN, attention weight and new features from each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f5176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"cancerdetection\"\n",
    "ntype = 2\n",
    "cv = 1\n",
    "feature_ex, y_ex, num_ex = data_prepare_external(path  = \"/home/wjs/hdd/DualPRE/code/datasplit/\", feature_matrix = f\"feature_valid_{task}_cv{cv}\", \n",
    "                                                 sampleset = f\"y_valid_{task}_cv{cv}\",internal = True)\n",
    "\n",
    "model = torch.load(f'./model/best_model_{task}_cv{cv}_B256.model')\n",
    "pred,output_dict = compute_test( model,device,feature_ex, y_ex,num_ex,ntype,drop_last=False)\n",
    "\n",
    "\n",
    "for name, matrix in output_dict.items():\n",
    "    matrix = matrix.cpu().detach().numpy()\n",
    "    file_path = os.path.join(\"/home/wjs/hdd/DualPRE/code/dict/\", f\"{task}_{name}.csv\")\n",
    "    df = pd.DataFrame(matrix) \n",
    "    df.to_csv(file_path, index=False, header=True) \n",
    "    print(f\"Matrix '{name}' saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c2138",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"BRCAsubtype\"\n",
    "ntype = 4\n",
    "cv = 1\n",
    "feature_ex, y_ex, num_ex = data_prepare_external(path  = \"/home/wjs/hdd/DualPRE/data/BRCAsubtype/\", feature_matrix = \"metabric_term\", sampleset = \"metabric_clinical_4subtype\",internal = False)\n",
    "model = torch.load(f'./model/best_model_{task}_cv{cv}_B64.model')\n",
    "pred,output_dict = compute_test( model,device,feature_ex, y_ex, num_ex, ntype,drop_last=False)\n",
    "os.makedirs(\"./dict\", exist_ok=True)\n",
    "\n",
    "for name, matrix in output_dict.items():\n",
    "    matrix = matrix.cpu().detach().numpy()\n",
    "    file_path = os.path.join(\"/home/wjs/hdd/DualPRE/code/dict/\", f\"{task}_{name}.csv\")\n",
    "    df = pd.DataFrame(matrix) \n",
    "    df.to_csv(file_path, index=False, header=True) \n",
    "    print(f\"Matrix '{name}' saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"CRCsubtype\"\n",
    "ntype = 4\n",
    "cv = 1\n",
    "feature_ex, y_ex, num_ex = data_prepare_external(path  = \"/home/wjs/hdd/DualPRE/data/CRCsubtype/\", feature_matrix = \"CRC_geo\", sampleset = \"CRC_label_geo\",internal = False)\n",
    "model = torch.load(f'./model/best_model_{task}_cv{cv}_B64.model')\n",
    "pred,output_dict = compute_test(model, device, feature_ex, y_ex, num_ex,ntype,drop_last=False)\n",
    "\n",
    "for name, matrix in output_dict.items():\n",
    "    matrix = matrix.cpu().detach().numpy()\n",
    "    file_path = os.path.join(\"/home/wjs/hdd/DualPRE/code/dict/\", f\"{task}_{name}.csv\")\n",
    "    df = pd.DataFrame(matrix) \n",
    "    df.to_csv(file_path, index=False, header=True) \n",
    "    print(f\"Matrix '{name}' saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b8896",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "\n",
    "task = \"survival\"\n",
    "cv = 1\n",
    "feature_ex, y_ex, num_ex = data_prepare_external_surv(path  = \"/home/wjs/hdd/DualPRE/code/datasplit/\", feature_matrix = f\"feature_valid_{task}_cv{cv}\", \n",
    "                                                 sampleset = f\"y_valid_{task}_cv{cv}\",internal = True)\n",
    "\n",
    "model = torch.load(f'./model/best_model_{task}_cv{cv}_B512.model')\n",
    "pred,output_dict = compute_test_surv( model,device,feature_ex, y_ex, num_ex,drop_last=False)\n",
    "\n",
    "\n",
    "for name, matrix in output_dict.items():\n",
    "    matrix = matrix.cpu().detach().numpy()\n",
    "    file_path = os.path.join(\"/home/wjs/hdd/DualPRE/code/dict/\", f\"{task}_{name}.csv\")\n",
    "    df = pd.DataFrame(matrix) \n",
    "    df.to_csv(file_path, index=False, header=True) \n",
    "    print(f\"Matrix '{name}' saved to {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
