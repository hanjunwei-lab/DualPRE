{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import r2_score, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from utils import *\n",
    "from model import *\n",
    "from trainer import *\n",
    "import torch.utils.data as Dataset\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "# Training settings\n",
    "sys.argv = sys.argv[:1]\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=0, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=150, help='Number of epochs to train.')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='Initial learning rate.')\n",
    "parser.add_argument('--batch', type=int, default=256, help='Number of batch size.')\n",
    "parser.add_argument('--n_heads', type=int, default=3, help='Number of head attentions.')\n",
    "parser.add_argument('--alpha', type=float, default=0.2, help='Alpha for the leaky_relu.')\n",
    "parser.add_argument('--patience', type=int, default=10, help='')\n",
    "parser.add_argument('--nOutputGAT_p', type=int, default=343, help='')\n",
    "parser.add_argument('--nOutputGAT_c', type=int, default=86, help='')\n",
    "parser.add_argument('--ntype', type=int, default=2, help='Number of predicted sample type.')\n",
    "parser.add_argument('--d_k', type=int, default=32, help='')\n",
    "parser.add_argument('--datapath', type=str, default=\"\", help='')\n",
    "parser.add_argument('--step_size', type=int, default=30, help='')\n",
    "parser.add_argument('--gamma', type=float, default=0.5, help='')\n",
    "parser.add_argument('--gain', type=float, default=1.414, help='')\n",
    "parser.add_argument('--task', type=str, default=\"\", help='Name of the task.')\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    \n",
    "\n",
    "activation_function = nn.ReLU()\n",
    "args.task = \"cancerdetection\"\n",
    "args.epochs = 30\n",
    "args.batch = 256\n",
    "args.lr = 1e-4\n",
    "args.dropout_rate = 0.5\n",
    "\n",
    "args.ntype = 2\n",
    "args.d_k = 32\n",
    "args.nheads = 3\n",
    "args.nOutputGAT_p = 343\n",
    "args.nOutputGAT_c = 86\n",
    "args.adp_hidden_dims = [100]\n",
    "args.adp_code_dim = 50\n",
    "args.adc_hidden_dims = [50]\n",
    "args.adc_code_dim = 30\n",
    "args.gain = 1.414\n",
    "args.code_dropout = True\n",
    "args.alpha = 0.2\n",
    "pgraph_k=2\n",
    "cgraph_k=2\n",
    "\n",
    "fm = \"Pancancer_disease_exp\"\n",
    "ss = \"Pancancer_disease_label\"\n",
    "args.datapath = \"/home/wjs/hdd/DualPRE/data/cancerdetection/\"\n",
    "\n",
    "\n",
    "args.patience = 10\n",
    "args.gamma = 0.5\n",
    "args.step_size = 30\n",
    "args.early_stop_delta = 0.0001\n",
    "num_folds = 1 \n",
    "save = True\n",
    "drop_last = False\n",
    "cv_results = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for cv in range(1, num_folds + 1):\n",
    "    print(f\"Starting {cv}th fold of cross-validation\")\n",
    "    \n",
    "\n",
    "    feature_train, y_train, feature_valid, y_valid = data_prepare_train(\n",
    "        path=args.datapath, \n",
    "        feature_matrix=fm, \n",
    "        sampleset=ss\n",
    "    )\n",
    "    if save:  \n",
    "        os.makedirs(\"datasplit\", exist_ok=True)\n",
    "        np.savetxt(os.path.join(\"datasplit\", f'feature_valid_{args.task}_cv{cv}.csv'), feature_valid.T.detach().numpy(), fmt='%.6f', delimiter=',')\n",
    "        np.savetxt(os.path.join(\"datasplit\", f'y_valid_{args.task}_cv{cv}.csv'), y_valid.detach().numpy(), fmt='%.6f', delimiter=',')\n",
    "        \n",
    "    \n",
    "    counts = torch.bincount(y_train.long(), minlength=args.ntype)\n",
    "\n",
    "    weights = 1 / counts.float()\n",
    "\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    loss_func = nn.CrossEntropyLoss(weight=weights)\n",
    "    loss_func.to(device)\n",
    "    \n",
    "    adp = Autodecoder(input_dim=args.nOutputGAT_p, \n",
    "                                    hidden_dims=args.adp_hidden_dims, \n",
    "                                    code_dim=args.adp_code_dim,\n",
    "                                    code_activation=True, dropout=args.code_dropout, dropout_rate=args.dropout_rate)\n",
    "    \n",
    "    adc = Autodecoder(input_dim=args.nOutputGAT_c, \n",
    "                                    hidden_dims=args.adc_hidden_dims, \n",
    "                                    code_dim=args.adc_code_dim,\n",
    "                                    code_activation=True, dropout=args.code_dropout, dropout_rate=args.dropout_rate)\n",
    "    \n",
    "\n",
    "    \n",
    "    model = DualPRE(device,\n",
    "                Autodecoder_p=adp,\n",
    "                Autodecoder_c=adc,\n",
    "                npath=343,\n",
    "                ncell=86,\n",
    "                hidden = [args.adp_code_dim,args.adc_code_dim],\n",
    "                nOutputGAT_p=args.nOutputGAT_p,\n",
    "                nOutputGAT_c=args.nOutputGAT_c,\n",
    "                pgraph_k=pgraph_k,\n",
    "                cgraph_k=cgraph_k,\n",
    "                d_k=args.d_k,\n",
    "                nheads=args.n_heads,\n",
    "                ntype=args.ntype,\n",
    "                alpha=args.alpha,\n",
    "                activation_function = activation_function,\n",
    "                dropout_rate= args.dropout_rate).to(device)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam([{'params': model.psample_MultiHead1.parameters(), 'lr': 1e-4},  \n",
    "                            {'params': model.psample_attentions1.parameters(), 'lr': 1e-4},\n",
    "                            {'params': model.csample_MultiHead1.parameters(), 'lr': 1e-4},\n",
    "                            {'params': model.csample_attentions1.parameters(), 'lr': 1e-4},\n",
    "                            {'params': model.Autodecoder_p.parameters(), 'lr': 1e-3},\n",
    "                            {'params': model.Autodecoder_c.parameters(), 'lr': 1e-3},\n",
    "                            {'params': model.FClayer1.parameters(), 'lr': 1e-3},  \n",
    "                            {'params': model.FClayer2.parameters(), 'lr': 1e-3},  \n",
    "                            {'params': model.FClayer3.parameters(), 'lr': 1e-3}\n",
    "                            ], weight_decay=1e-5)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n",
    "\n",
    "    valid_loss = [0]\n",
    "    bad_counter = 0\n",
    "    t_total = time.time()\n",
    "    bv = [0,1]\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        print(f\"Epoch {epoch+1}/{args.epochs} in fold {cv}\")\n",
    "        best_epoch, loss, f1 = train(epoch, model, device, optimizer, loss_func, feature_train, y_train, feature_valid, y_valid, args.batch, args.task, args.ntype, cv ,best_value = bv, save = save,drop_last=drop_last)\n",
    "        valid_loss.append(loss)\n",
    "\n",
    "        if abs(valid_loss[-2] - valid_loss[-1]) <= args.early_stop_delta:\n",
    "            bad_counter += 1\n",
    "        else:\n",
    "            bad_counter = 0\n",
    "        if bad_counter >= args.patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1} in fold {cv}\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if save:\n",
    "            os.makedirs(\"./model\", exist_ok=True)\n",
    "            torch.save(model, f\"./model/last_model_{args.task}_cv{cv}_B{args.batch}_L{args.lr}.model\")\n",
    "\n",
    "    print(f\"Optimization Finished for fold {cv}. Total time: {time.time() - t_total:.4f}s\")\n",
    "    print(f\"Loading best epoch {best_epoch} for fold {cv}\")\n",
    "\n",
    "   \n",
    "    cv_results.append({\n",
    "        \"fold\": cv,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"best_validation_f1\": f1\n",
    "    })\n",
    "\n",
    "print(\"Cross-validation results:\", cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  External test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cv = 1\n",
    "feature_ex, y_ex, num_ex = data_prepare_external(path  = args.datapath, feature_matrix = \"GDC CPTAC-3_disease_exp\", sampleset = \"GDC CPTAC-3_disease_label\",internal = False)\n",
    "\n",
    "model = torch.load(f'./model/best_model_{args.task}_cv{cv}_B256.model')\n",
    "pred,output_dict = compute_test( model,device,feature_ex, y_ex,256,args.ntype,drop_last)\n",
    "\n",
    "output_file1 = os.path.join(\"pred\", f'pred_ex_cancerdetection.csv')\n",
    "np.savetxt(output_file1, np.array(pred.cpu()), fmt='%.6f', delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
